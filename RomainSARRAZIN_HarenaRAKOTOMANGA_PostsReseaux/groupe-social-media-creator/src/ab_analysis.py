"""
Module d'analyse comparative pour les tests A/B de posts rÃ©seaux sociaux.

Fournit des fonctions Python pures (sans HTML/CSS) pour :
- Afficher chaque test (A, B, â€¦) comme un post complet prÃªt-Ã -publier
- Comparer les deux propositions cÃ´te Ã  cÃ´te
- Identifier les forces et faiblesses de chaque version
- Produire une recommandation argumentÃ©e
"""

from typing import Any, Dict, List
from collections import Counter


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Constantes
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCORE_TO_NUM = {
    "excellent": 95,
    "Ã©levÃ©": 90,
    "bon": 70,
    "moyen": 60,
    "faible": 30,
}

RELEVANCE_TO_NUM = {
    "haute": 3,
    "moyenne": 2,
    "basse": 1,
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Extraction de mÃ©triques
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_variation_metrics(variation) -> Dict[str, Any]:
    """
    Extrait un dictionnaire de mÃ©triques Ã  partir d'une ABVariation.
    """
    post = variation.post
    hashtags = post.hashtags

    relevance_counts = Counter(h.relevance for h in hashtags)
    hashtag_score = sum(RELEVANCE_TO_NUM.get(h.relevance, 1) for h in hashtags)

    texte = post.texte
    nb_mots = len(texte.split())

    return {
        "version": variation.version,
        "strategie": variation.strategie,
        "score_estime": variation.score_estime,
        "score_numerique": SCORE_TO_NUM.get(
            variation.score_estime.lower().strip(), 50
        ),
        "longueur_caracteres": post.longueur_caracteres,
        "nb_mots": nb_mots,
        "nb_lignes": texte.count("\n") + 1,
        "nb_questions": texte.count("?"),
        "nb_exclamations": texte.count("!"),
        "nb_emojis": len(post.emojis_utilises),
        "emojis": post.emojis_utilises,
        "accroche": post.accroche,
        "call_to_action": post.call_to_action,
        "nb_hashtags": len(hashtags),
        "hashtags_haute": relevance_counts.get("haute", 0),
        "hashtags_moyenne": relevance_counts.get("moyenne", 0),
        "hashtags_basse": relevance_counts.get("basse", 0),
        "hashtag_score": hashtag_score,
        "hashtags_list": ["#" + h.tag for h in hashtags],
        "image_style": post.image_prompt.style,
        "image_couleurs": post.image_prompt.couleurs_dominantes,
        "image_prompt_en": post.image_prompt.prompt_en,
        "meilleur_creneau": (
            f"{post.timing[0].jour} Ã  {post.timing[0].heure}"
            if post.timing
            else "N/A"
        ),
        "timing_raison": (
            post.timing[0].raison if post.timing else ""
        ),
    }


def extract_all_metrics(ab_output) -> List[Dict[str, Any]]:
    """Extrait les mÃ©triques de toutes les variations."""
    return [extract_variation_metrics(var) for var in ab_output.variations]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Analyse comparative
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def compare_variations(ab_output) -> Dict[str, Any]:
    """
    Compare les variations A/B et produit une analyse structurÃ©e.

    Returns:
        Dictionnaire contenant : metrics, classement, differences,
        hashtags_communs, hashtags_uniques, recommandation, etc.
    """
    metrics = extract_all_metrics(ab_output)
    classement = sorted(
        metrics, key=lambda m: m["score_numerique"], reverse=True
    )

    criteres_num = [
        ("score_numerique", "Score d'engagement", True),
        ("longueur_caracteres", "Longueur du texte", None),
        ("nb_mots", "Nombre de mots", None),
        ("nb_hashtags", "Nombre de hashtags", True),
        ("hashtag_score", "QualitÃ© des hashtags", True),
        ("nb_emojis", "Emojis", None),
        ("nb_questions", "Questions posÃ©es", True),
    ]

    differences = []
    for key, label, higher_is_better in criteres_num:
        values = {m["version"]: m[key] for m in metrics}
        best_v = max(values, key=values.get)
        worst_v = min(values, key=values.get)
        if values[best_v] != values[worst_v]:
            differences.append({
                "critere": label,
                "valeurs": values,
                "ecart": values[best_v] - values[worst_v],
                "leader": best_v if higher_is_better else None,
            })

    hashtag_sets = {m["version"]: set(m["hashtags_list"]) for m in metrics}
    if len(hashtag_sets) >= 2:
        communs = set.intersection(*hashtag_sets.values())
        uniques = {v: tags - communs for v, tags in hashtag_sets.items()}
    else:
        communs = set()
        uniques = {}

    return {
        "metrics": metrics,
        "classement": classement,
        "differences": differences,
        "hashtags_communs": communs,
        "hashtags_uniques": uniques,
        "recommandation": ab_output.recommandation,
        "criteres_evaluation": ab_output.criteres_evaluation,
        "plateforme": ab_output.plateforme,
        "sujet": ab_output.sujet,
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Affichage â€” Test A / Test B (posts complets)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def print_test(ab_output, version: str) -> None:
    """
    Affiche UN test (A ou B) comme un post complet prÃªt-Ã -publier.

    Args:
        ab_output: Instance ABTestOutput
        version: Lettre de la version Ã  afficher ("A", "B", "C"â€¦)
    """
    var = None
    for v in ab_output.variations:
        if v.version.upper() == version.upper():
            var = v
            break
    if var is None:
        versions = ", ".join(v.version for v in ab_output.variations)
        print(f"âŒ Version '{version}' introuvable. Versions disponibles : {versions}")
        return

    post = var.post
    w = 65

    print(f"\n{'â•”' + 'â•' * (w - 2) + 'â•—'}")
    print(f"â•‘{'TEST ' + var.version:^{w - 2}}â•‘")
    print(f"â•‘{ab_output.plateforme.upper():^{w - 2}}â•‘")
    print(f"{'â•š' + 'â•' * (w - 2) + 'â•'}")

    print(f"\n  StratÃ©gie : {var.strategie}")
    print(f"  Score estimÃ© : {var.score_estime}")

    # --- Le post tel qu'il serait publiÃ© ---
    print(f"\n{'â”Œ' + 'â”€' * (w - 2) + 'â”'}")
    print(f"â”‚{'POST TEL QU IL SERAIT PUBLIÃ‰':^{w - 2}}â”‚")
    print(f"{'â”œ' + 'â”€' * (w - 2) + 'â”¤'}")

    for line in post.texte.split("\n"):
        # DÃ©couper les lignes trop longues
        while len(line) > w - 4:
            print(f"â”‚ {line[:w - 4]:<{w - 3}}â”‚")
            line = line[w - 4:]
        print(f"â”‚ {line:<{w - 3}}â”‚")

    print(f"â”‚{' ' * (w - 2)}â”‚")
    hashtags_str = " ".join("#" + h.tag for h in post.hashtags)
    # Afficher les hashtags (peut Ãªtre long)
    while len(hashtags_str) > w - 4:
        print(f"â”‚ {hashtags_str[:w - 4]:<{w - 3}}â”‚")
        hashtags_str = hashtags_str[w - 4:]
    print(f"â”‚ {hashtags_str:<{w - 3}}â”‚")
    print(f"{'â””' + 'â”€' * (w - 2) + 'â”˜'}")

    # --- DÃ©tails ---
    print(f"\n  ğŸ¯ Accroche : \"{post.accroche}\"")
    print(f"  ğŸ“¢ CTA      : {post.call_to_action}")
    print(f"  ğŸ“ Longueur  : {post.longueur_caracteres} caractÃ¨res, {len(post.texte.split())} mots")
    print(f"  ğŸ˜€ Emojis    : {' '.join(post.emojis_utilises[:8]) if post.emojis_utilises else '(aucun)'}")

    print(f"\n  ğŸ·ï¸  Hashtags ({len(post.hashtags)}) :")
    for h in post.hashtags:
        print(f"      #{h.tag:<25} pertinence: {h.relevance}")

    if post.timing:
        print(f"\n  â° CrÃ©neaux recommandÃ©s :")
        for t in post.timing[:3]:
            print(f"      {t.jour} Ã  {t.heure} â€” {t.raison} [{t.score_engagement}]")

    print(f"\n  ğŸ¨ Image DALL-E 3 :")
    print(f"      Style    : {post.image_prompt.style}")
    print(f"      Couleurs : {', '.join(post.image_prompt.couleurs_dominantes)}")
    print(f"      Prompt   : {post.image_prompt.prompt_en[:120]}...")
    print()


def print_test_a(ab_output) -> None:
    """Affiche le TEST A (premiÃ¨re variation) comme post complet."""
    if ab_output.variations:
        print_test(ab_output, ab_output.variations[0].version)


def print_test_b(ab_output) -> None:
    """Affiche le TEST B (deuxiÃ¨me variation) comme post complet."""
    if len(ab_output.variations) >= 2:
        print_test(ab_output, ab_output.variations[1].version)


def print_all_tests(ab_output) -> None:
    """Affiche tous les tests (A, B, Câ€¦) l'un aprÃ¨s l'autre."""
    print(f"\n{'â•' * 65}")
    print(f"  ğŸ”¬ TEST A/B â€” {ab_output.plateforme.upper()}")
    print(f"  ğŸ“Œ Sujet : {ab_output.sujet}")
    print(f"  ğŸ“Š {len(ab_output.variations)} propositions gÃ©nÃ©rÃ©es par l'IA")
    print(f"{'â•' * 65}")

    for var in ab_output.variations:
        print_test(ab_output, var.version)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Comparaison directe A vs B
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def print_comparaison(ab_output) -> None:
    """
    Compare les tests A et B (et Câ€¦) cÃ´te Ã  cÃ´te.
    Montre un tableau de mÃ©triques puis les diffÃ©rences clÃ©s
    pour aider Ã  choisir le meilleur post.
    """
    analysis = compare_variations(ab_output)
    metrics = analysis["metrics"]

    print(f"\n{'â•' * 65}")
    print(f"  ğŸ“Š COMPARAISON : ", end="")
    print(" vs ".join(f"TEST {m['version']}" for m in metrics))
    print(f"{'â•' * 65}")

    # Tableau de mÃ©triques
    print(f"\n{'â”€' * 65}")
    header = f"  {'CritÃ¨re':<28}"
    for m in metrics:
        header += f" â”‚ {'Test ' + m['version']:>10}"
    print(header)
    print(f"{'â”€' * 65}")

    rows = [
        ("Score engagement", "score_numerique", "/100"),
        ("CaractÃ¨res", "longueur_caracteres", ""),
        ("Mots", "nb_mots", ""),
        ("Questions (?)", "nb_questions", ""),
        ("Exclamations (!)", "nb_exclamations", ""),
        ("Emojis", "nb_emojis", ""),
        ("Hashtags", "nb_hashtags", ""),
        ("  dont haute pertinence", "hashtags_haute", ""),
        ("QualitÃ© hashtags", "hashtag_score", "pts"),
    ]

    for label, key, unit in rows:
        line = f"  {label:<28}"
        values = [m[key] for m in metrics]
        best = max(values)
        for val in values:
            marker = " â˜…" if val == best and values.count(best) == 1 else ""
            line += f" â”‚ {str(val) + unit:>10}{marker}"
        print(line)

    print(f"{'â”€' * 65}")
    print("  â˜… = meilleure valeur\n")

    # DiffÃ©rences clÃ©s
    print(f"  ğŸ¯ ACCROCHES :")
    for m in metrics:
        print(f"    Test {m['version']} : \"{m['accroche']}\"")

    print(f"\n  ğŸ“¢ APPELS Ã€ L'ACTION :")
    for m in metrics:
        print(f"    Test {m['version']} : {m['call_to_action']}")

    print(f"\n  ğŸ¨ STYLES D'IMAGE :")
    for m in metrics:
        couleurs = ", ".join(m["image_couleurs"][:3])
        print(f"    Test {m['version']} : {m['image_style']} ({couleurs})")

    # Hashtags communs / uniques
    communs = analysis["hashtags_communs"]
    uniques = analysis["hashtags_uniques"]

    if communs:
        print(f"\n  ğŸ·ï¸  HASHTAGS EN COMMUN ({len(communs)}) :")
        print(f"    {' '.join(sorted(communs))}")

    if uniques:
        print(f"\n  ğŸ·ï¸  HASHTAGS UNIQUES :")
        for version, tags in uniques.items():
            if tags:
                print(f"    Test {version} uniquement : {' '.join(sorted(tags))}")
            else:
                print(f"    Test {version} : (tous en commun)")
    print()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Verdict final
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def print_verdict(ab_output) -> None:
    """
    Affiche le verdict final : classement des tests et
    recommandation de l'IA sur lequel choisir.
    """
    analysis = compare_variations(ab_output)
    classement = analysis["classement"]

    print(f"\n{'â•' * 65}")
    print(f"  ğŸ† VERDICT : QUEL TEST CHOISIR ?")
    print(f"{'â•' * 65}")

    medals = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "4ï¸âƒ£"]
    print(f"\n  Classement par score d'engagement :\n")
    for i, m in enumerate(classement):
        medal = medals[i] if i < len(medals) else f"#{i + 1}"
        bar_len = m["score_numerique"] // 5
        bar = "â–ˆ" * bar_len + "â–‘" * (20 - bar_len)
        print(f"   {medal} TEST {m['version']} â”‚ {bar} â”‚ {m['score_numerique']}/100 ({m['score_estime']})")
        print(f"          StratÃ©gie : {m['strategie']}")

    print(f"\n{'â”€' * 65}")
    print(f"  âœ… Recommandation de l'IA :")
    print(f"  {analysis['recommandation']}")
    print(f"{'â”€' * 65}")
    print(f"  CritÃ¨res d'Ã©valuation utilisÃ©s :")
    for c in analysis["criteres_evaluation"]:
        print(f"    â€¢ {c}")
    print()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Analyse complÃ¨te
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def print_ab_full_analysis(ab_output) -> None:
    """
    Lance l'analyse complÃ¨te :
    1. Affiche chaque test (post complet)
    2. Comparaison cÃ´te Ã  cÃ´te
    3. Verdict et recommandation
    """
    print_all_tests(ab_output)
    print_comparaison(ab_output)
    print_verdict(ab_output)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Anciens noms (rÃ©tro-compatibilitÃ©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def print_ab_summary(ab_output) -> None:
    """Alias â†’ print_comparaison."""
    print_comparaison(ab_output)

def print_ab_texts(ab_output) -> None:
    """Alias â†’ print_all_tests."""
    print_all_tests(ab_output)

def print_ab_differences(ab_output) -> None:
    """Alias â†’ print_comparaison (inclut les diffÃ©rences)."""
    print_comparaison(ab_output)

def print_ab_recommendation(ab_output) -> None:
    """Alias â†’ print_verdict."""
    print_verdict(ab_output)
